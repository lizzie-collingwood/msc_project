import json
import ast
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
plt.style.use('ggplot')
plt.rcParams['mathtext.fontset'] = 'stix'
plt.rcParams['font.family'] = 'STIXGeneral'
import cmasher as cmr


class AnalyseJson:
    """Opens and extracts data and info from the json output of sw_energy.py."""
    column_dict = {
        1: {'ylab': 'Total mass (kg)'},
        2: {'ylab': 'Energy'},
        3: {'ylab': 'Absolute vorticity'},
        4: {'ylab': 'Total enstrophy'},
        5: {'ylab': 'Linear iterations'},
        6: {'ylab': 'Nonlinear iterations'},
        7: {'ylab': 'Execution time'}}
    leg_dict = {
        'poisson': {'rename': '', 'options': {'True': 'PI', 'False': 'IMR', 'Picard': 'Picard'}},
        'upwind': {'rename': '', 'options': {'True': 'Upwind', 'False': 'Average'}},
        'dt': {'rename': 'Time step (hours)'},
        'snes_rtol': {'rename': 'Nonlinear stopping criteration: relative residual norm'},
        'rtol': {'rename': 'Linear stopping criteration: relative residual norm'},
        'atol': {'rename': 'Linear stopping criteration: absolute residual norm'},
        'softsign': {'rename': '$a$ ='},
    }
    ignore_dict = ['base_level']

    def __init__(self, file=None):
        if file is not None:
            self.array, self.options = self.read_json(jsonfile=file)

    def read_json(self, jsonfile):
        """Read, load, and plot data held in JSON file: mass, energy, abs vorticity, and enstrophy."""
        # Load JSON file
        with open(jsonfile) as f:
            jsondata = json.load(f)

            # Extract the option information
            options = jsondata['options']

            # Extract the keys and values and concatenate
            data = jsondata['data']

        times = np.asarray(list(data), dtype=float) / (3600*24)
        vals = np.asarray(list(data.values()), dtype=float)
        return np.r_['1,2,0', times, vals], options

    def extract(self, kwargs):
        """Extract the data and options info from json files."""
        arrs, ops = {}, []
        for key, value in kwargs.items():
            arr, op = self.read_json(jsonfile=value)
            arrs.update({key: arr})
            ops.append(ast.literal_eval(op))

        # Combine the option data into one dict.
        ops = {k: [d[k] for d in ops] for k in ops[0]}
        return arrs, ops

    @staticmethod
    def find_test_parameters(leg_dict, ops, ignore_dict):
        """
        Finds the test parameters given options dict.
        :param ops: dict, contains the parser arg output from sw_energy.py.
        :return out: outputs the labels of the datasets in terms of the test parameter(s).
        """
        out = []
        for k, vals in ops.items():
            if k in ignore_dict: continue
            if len(set(vals))>1:
                labs = list(map(str, vals))
                K = k + ': '
                try:
                    K = leg_dict[k]['rename'] + ' '
                    try:
                        labs = [leg_dict[k]['options'][l] for l in labs]
                    except: pass
                except: pass

                if len(out)==0:
                    out = [K+l for l in labs]
                else:
                    out = [out[i]+', '+K+labs[i] for i in range(len(labs))]
        
        if len(out)==0: out = [' ']
        return out

    @staticmethod
    def normalise(slice):
        """Normalise the data slice according to the initial value."""
        return (slice - slice[0]) / slice[0]

    def multiplot(self, normalise=False, semilog=False, cumsum=False, cmap='viridis', colnum=1, **kwargs):
        """
        Plot multiple json file data.
        :param kwargs: any number of strings describing path to json files.
        :param normalise: bool, whether to normalise the data according to initial value.
        :param semilog: bool, whether to scale the y axis using semilog.
        :param colnum: int, identifies which column of the output array to plot.
        """
        # Set the colour scheme
        colours = cmr.take_cmap_colors(cmap, len(kwargs), return_fmt='hex')

        # Extract data, options and labels from json files.
        arrs, ops = self.extract(kwargs)
        labels = self.find_test_parameters(self.leg_dict, ops, self.ignore_dict)

        # Plot the json data
        plt.figure()
        for i, (_, arr) in enumerate(arrs.items()):
            if normalise: column = self.normalise(arr[1:, colnum])
            else: column = arr[1:, colnum]
            if cumsum: column = np.cumsum(column)
            if semilog: plt.semilogy(arr[1:, 0], np.abs(column), label=labels[i], color=colours[i])
            else: plt.plot(arr[1:, 0], column, label=labels[i], color=colours[i])
            
        # Axes labels
        plt.xlabel('Time (days)')
        if normalise: plt.ylabel('Relative error: '+self.column_dict[colnum]['ylab'])
        else: plt.ylabel(self.column_dict[colnum]['ylab'])

        # Xtick labels + legend
        dmax = max(ops['dmax'])
        plt.xticks(np.arange(dmax+1))
        if len(kwargs)>1: plt.legend()
        plt.show()

    def perinf(self, **kwargs):
        """
        Print performance information and measurements.
        """
        # Extract data, options and labels from json files.
        arrs, ops = self.extract(kwargs)
        labels = self.find_test_parameters(self.leg_dict, ops, self.ignore_dict)
        # print(labels)
        cols = [5, 6, 7]
        
        # Extract and compute relevant performance measures.
        totdata = {}
        for i, (j, arr) in enumerate(arrs.items()):
            # Get data about totals
            tots = [np.sum(arr[:, i]) for i in cols]
            tots.append(arr.shape[0])
            totdata.update({j: tots})
        
        # Combine data into a dataframe.
        data = np.array([totdata[i] for i in totdata.keys()])
        columns = [self.column_dict[i]['ylab'] for i in cols]
        columns.append('No. timesteps')
        df = pd.DataFrame(data, index=labels, columns=columns)

        # Add extra columns

        print(df)

# Provide path to JSON files
f1 = '/Users/lizziecollingwood/MSc./proj/simulations/w5/ref2/PI/upwind/w5aug.json'
f1a = '/Users/lizziecollingwood/MSc./proj/simulations/w5/ref2/PI/upwind/NEWENERGY/w5aug.json'
f2 = '/Users/lizziecollingwood/MSc./proj/simulations/w5/ref2/IMR/upwind/w5aug.json'
f3 = '/Users/lizziecollingwood/MSc./proj/simulations/w5/ref2/IMR/avg/w5aug.json'
f4 = '/Users/lizziecollingwood/MSc./proj/simulations/w5/ref2/PI/avg/w5aug.json'
f5 = '/Users/lizziecollingwood/MSc./proj/simulations/w5/ref2/PI/avg/atoln12/w5aug.json'
f6 = '/Users/lizziecollingwood/MSc./proj/simulations/w5/ref4/PI/avg/w5aug.json'
f7 = '/Users/lizziecollingwood/MSc./proj/simulations/w5/ref4/PI/upwind/a0/w5aug.json'
f8 = '/Users/lizziecollingwood/MSc./proj/simulations/w5/ref4/PI/upwind/a20/w5aug.json'
f9 = '/Users/lizziecollingwood/MSc./proj/simulations/w5/ref4/PI/upwind/a2/w5aug.json'
f10 = '/Users/lizziecollingwood/MSc./proj/simulations/w5/ref4/PI/upwind/a40/w5aug.json'
f11 = '/Users/lizziecollingwood/MSc./proj/simulations/w5/ref4/PI/upwind/a80/w5aug.json'
f12 = '/Users/lizziecollingwood/MSc./proj/simulations/w5/ref4/PI/upwind/a160/w5aug.json'
f13 = '/Users/lizziecollingwood/MSc./proj/simulations/w5/ref5/PI/avg/w5aug.json'
f14 = '/Users/lizziecollingwood/MSc./proj/simulations/w5/ref5/IMR/avg/w5aug.json'
f15 = '/Users/lizziecollingwood/MSc./proj/simulations/w5/ref5/PI/upwind/w5aug.json'

# Initialise class and implement method
aj = AnalyseJson()

# Energy
# aj.multiplot(j3=f7, j2=f9, j1=f8, j4=f10, j6=f11, j7=f12, j5=f6, colnum=2, normalise=True, semilog=True, cmap='coolwarm')

aj.multiplot(j1=f13, j2=f14, j3=f15, colnum=2, normalise=True, semilog=True, cmap='coolwarm')
# aj.perinf(j3=f13, j2=f14)

# aj.multiplot(j7=f12, colnum=2, normalise=True, semilog=True, cmap='coolwarm')
# aj.multiplot(j6=f11, colnum=2, normalise=True, semilog=True, cmap='coolwarm')




# ====== COLOURMAPS
# seismic
# winter
# inferno
# cool
# plasma
# Set2
# ocean / gist_earth / 
